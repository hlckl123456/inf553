{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepConn_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ERAQJLhYInKN",
        "colab_type": "code",
        "outputId": "a0c8bb44-287d-4726-b2cf-aae5e458346a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# modeling imports\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers.merge import Add, Dot, Concatenate\n",
        "\n",
        "# preprocessing imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V2jtTbKEFoxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "class StackedNN():\n",
        "  def __init__(self,train_user,train_business,alpha,output_dim=5):\n",
        "        \n",
        "        # the shape of one training example is\n",
        "\n",
        "        user_inp, user_model = self.createModel(train_user)\n",
        "        business_inp, business_model = self.createModel(train_business)\n",
        "        stacked_layer = Concatenate()([user_model,business_model])\n",
        "        output_layer =  Dense(32, activation='relu')(stacked_layer)\n",
        "        output_layer = Dense(output_dim,activation='softmax')(output_layer)\n",
        "        self.model = Model(inputs=[user_inp, business_inp],outputs=output_layer)\n",
        "        self.model.compile(optimizer=keras.optimizers.Adam(alpha), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        \n",
        "        \n",
        "  def createModel(self,training_data):\n",
        "        input_shape = training_data.shape[1]\n",
        "        inp_layer = Input(shape=(input_shape,))\n",
        "        dense_layer = Dense(units=64, activation='relu')(inp_layer)\n",
        "        dense_layer = Dense(units=32, activation='relu')(dense_layer)\n",
        "\n",
        "        #model.add(Dense(units=5, activation='softmax'))\n",
        "        return inp_layer, dense_layer\n",
        "   \n",
        "  def train(self,train_user,train_business,output_rating,num_iter):\n",
        "        train_inputs = [train_user, train_business] \n",
        "        self.model.fit(train_inputs, output_rating, epochs=num_iter)\n",
        "  \n",
        " \n",
        "   \n",
        "  \n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4V9D798oM2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras.layers import Concatenate\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqQg19YhJJtm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_user = pd.read_csv(\"LDA Modelling/results/train/user_FeatureVec.csv\").drop([\"user_id\",\"review_id\",\"business_id\",\"1overN\",\"2overN\",\"percentile\"],axis=1).fillna(0)\n",
        "train_business = pd.read_csv(\"LDA Modelling/results/train/business_FeatureVec.csv\").drop([\"business_id\",\"review_id\",\"user_id\",\"1overN\",\"2overN\",\"percentile\"],axis=1).fillna(0)\n",
        "#train_business = train_business.loc[:,[\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\",\"topic_10\",\"topic_11\",\"topic_12\",\"topic_13\",\"topic_14\",\"topic_15\",\"topic_16\",\"topic_17\",\"topic_18\",\"topic_19\",\"business_stars\",\"is_open\",\"attributes.Ambience.casual\",\"attributes.BikeParking\",\"attributes.BusinessAcceptsCreditCards\",\"attributes.BusinessParking.street\",\"attributes.HasTV\",\"attributes.RestaurantsDelivery\",\"attributes.GoodForMeal.breakfast\",\"attributes.GoodForMeal.brunch\",\"attributes.GoodForMeal.dessert\",\"attributes.GoodForMeal.dinner\",\"attributes.GoodForMeal.latenight\",\"attributes.GoodForMeal.lunch\",\"attributes.Alcohol\",\"attributes.NoiseLevel\",\"attributes.RestaurantsPriceRange2\"]]\n",
        "stacked= train_business[['attributes.Ambience.casual','attributes.BikeParking','attributes.BusinessAcceptsCreditCards','attributes.BusinessParking.street','attributes.HasTV','attributes.RestaurantsDelivery','attributes.GoodForMeal.breakfast','attributes.GoodForMeal.brunch','attributes.GoodForMeal.dessert','attributes.GoodForMeal.dinner','attributes.GoodForMeal.latenight','attributes.GoodForMeal.lunch','attributes.Alcohol','attributes.NoiseLevel']].stack()\n",
        "train_business[['attributes.Ambience.casual','attributes.BikeParking','attributes.BusinessAcceptsCreditCards','attributes.BusinessParking.street','attributes.HasTV','attributes.RestaurantsDelivery','attributes.GoodForMeal.breakfast','attributes.GoodForMeal.brunch','attributes.GoodForMeal.dessert','attributes.GoodForMeal.dinner','attributes.GoodForMeal.latenight','attributes.GoodForMeal.lunch','attributes.Alcohol','attributes.NoiseLevel']]=pd.Series(stacked.factorize()[0], index=stacked.index).unstack()\n",
        "#reviews = pd.read_csv(\"user_business_reviewVec.csv\")['review_id']\n",
        "\n",
        "rating_csv = pd.read_csv(\"Dataset/PA/Restaurants/train/PA_train_yelp_academic_dataset_review.csv\")\n",
        "rating_csv_stars = rating_csv['stars']\n",
        "\n",
        "encoded_rating = to_categorical(np.array(list(rating_csv_stars)))\n",
        "encoded_rating_ = encoded_rating[:,1:]\n",
        "stackedModel = StackedNN(train_user,train_business,0.00000001,5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-c5_4JVTjKQ",
        "colab_type": "code",
        "outputId": "535f8b19-f293-4da9-fc2f-9c4f2256949d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16744
        }
      },
      "cell_type": "code",
      "source": [
        "stackedModel.train(train_user,train_business,encoded_rating_,500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "84887/84887 [==============================] - 11s 133us/step - loss: 2.2314 - acc: 0.1915\n",
            "Epoch 2/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.2302 - acc: 0.1916\n",
            "Epoch 3/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.2290 - acc: 0.1917\n",
            "Epoch 4/500\n",
            "84887/84887 [==============================] - 9s 108us/step - loss: 2.2278 - acc: 0.1919\n",
            "Epoch 5/500\n",
            "84887/84887 [==============================] - 11s 124us/step - loss: 2.2266 - acc: 0.1919\n",
            "Epoch 6/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.2254 - acc: 0.1920\n",
            "Epoch 7/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.2242 - acc: 0.1922\n",
            "Epoch 8/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.2231 - acc: 0.1922\n",
            "Epoch 9/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.2219 - acc: 0.1924\n",
            "Epoch 10/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.2207 - acc: 0.1925\n",
            "Epoch 11/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.2195 - acc: 0.1926\n",
            "Epoch 12/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.2183 - acc: 0.1927\n",
            "Epoch 13/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.2171 - acc: 0.1928\n",
            "Epoch 14/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.2160 - acc: 0.1929\n",
            "Epoch 15/500\n",
            "84887/84887 [==============================] - 8s 90us/step - loss: 2.2148 - acc: 0.1930\n",
            "Epoch 16/500\n",
            "84887/84887 [==============================] - 8s 97us/step - loss: 2.2136 - acc: 0.1931\n",
            "Epoch 17/500\n",
            "84887/84887 [==============================] - 8s 95us/step - loss: 2.2124 - acc: 0.1932\n",
            "Epoch 18/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.2112 - acc: 0.1934\n",
            "Epoch 19/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.2101 - acc: 0.1935\n",
            "Epoch 20/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.2089 - acc: 0.1936\n",
            "Epoch 21/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.2077 - acc: 0.1937\n",
            "Epoch 22/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.2066 - acc: 0.1938\n",
            "Epoch 23/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.2054 - acc: 0.1939\n",
            "Epoch 24/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.2043 - acc: 0.1940\n",
            "Epoch 25/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.2031 - acc: 0.1942\n",
            "Epoch 26/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.2019 - acc: 0.1943\n",
            "Epoch 27/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.2008 - acc: 0.1944\n",
            "Epoch 28/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1997 - acc: 0.1944\n",
            "Epoch 29/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1985 - acc: 0.1946\n",
            "Epoch 30/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1974 - acc: 0.1947\n",
            "Epoch 31/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1963 - acc: 0.1949\n",
            "Epoch 32/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1952 - acc: 0.1950\n",
            "Epoch 33/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1940 - acc: 0.1951\n",
            "Epoch 34/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1929 - acc: 0.1952\n",
            "Epoch 35/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1917 - acc: 0.1953\n",
            "Epoch 36/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1905 - acc: 0.1954\n",
            "Epoch 37/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1892 - acc: 0.1956\n",
            "Epoch 38/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1879 - acc: 0.1956\n",
            "Epoch 39/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1865 - acc: 0.1957\n",
            "Epoch 40/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1851 - acc: 0.1958\n",
            "Epoch 41/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 2.1837 - acc: 0.1959\n",
            "Epoch 42/500\n",
            "84887/84887 [==============================] - 8s 91us/step - loss: 2.1823 - acc: 0.1960\n",
            "Epoch 43/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1809 - acc: 0.1960\n",
            "Epoch 44/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1795 - acc: 0.1961\n",
            "Epoch 45/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1781 - acc: 0.1962\n",
            "Epoch 46/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1767 - acc: 0.1963\n",
            "Epoch 47/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.1753 - acc: 0.1964\n",
            "Epoch 48/500\n",
            "84887/84887 [==============================] - 7s 84us/step - loss: 2.1740 - acc: 0.1966\n",
            "Epoch 49/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1727 - acc: 0.1966\n",
            "Epoch 50/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1713 - acc: 0.1965\n",
            "Epoch 51/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1700 - acc: 0.1967\n",
            "Epoch 52/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1687 - acc: 0.1967\n",
            "Epoch 53/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1674 - acc: 0.1968\n",
            "Epoch 54/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1661 - acc: 0.1969\n",
            "Epoch 55/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1648 - acc: 0.1971\n",
            "Epoch 56/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1636 - acc: 0.1972\n",
            "Epoch 57/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1623 - acc: 0.1974\n",
            "Epoch 58/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1611 - acc: 0.1976\n",
            "Epoch 59/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1599 - acc: 0.1977\n",
            "Epoch 60/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1587 - acc: 0.1978\n",
            "Epoch 61/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1575 - acc: 0.1979\n",
            "Epoch 62/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1563 - acc: 0.1980\n",
            "Epoch 63/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1552 - acc: 0.1981\n",
            "Epoch 64/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1540 - acc: 0.1983\n",
            "Epoch 65/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1529 - acc: 0.1984\n",
            "Epoch 66/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1518 - acc: 0.1984\n",
            "Epoch 67/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1507 - acc: 0.1985\n",
            "Epoch 68/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1496 - acc: 0.1985\n",
            "Epoch 69/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1486 - acc: 0.1986\n",
            "Epoch 70/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1475 - acc: 0.1987\n",
            "Epoch 71/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1465 - acc: 0.1988\n",
            "Epoch 72/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1455 - acc: 0.1987\n",
            "Epoch 73/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1445 - acc: 0.1988\n",
            "Epoch 74/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1436 - acc: 0.1989\n",
            "Epoch 75/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1426 - acc: 0.1991\n",
            "Epoch 76/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1417 - acc: 0.1992\n",
            "Epoch 77/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1407 - acc: 0.1994\n",
            "Epoch 78/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 2.1398 - acc: 0.1997\n",
            "Epoch 79/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1389 - acc: 0.2000\n",
            "Epoch 80/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1381 - acc: 0.2002\n",
            "Epoch 81/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1372 - acc: 0.2006\n",
            "Epoch 82/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1363 - acc: 0.2008\n",
            "Epoch 83/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1355 - acc: 0.2010\n",
            "Epoch 84/500\n",
            "84887/84887 [==============================] - 7s 82us/step - loss: 2.1347 - acc: 0.2013\n",
            "Epoch 85/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1338 - acc: 0.2014\n",
            "Epoch 86/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1330 - acc: 0.2015\n",
            "Epoch 87/500\n",
            "84887/84887 [==============================] - 7s 82us/step - loss: 2.1322 - acc: 0.2016\n",
            "Epoch 88/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1314 - acc: 0.2017\n",
            "Epoch 89/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1306 - acc: 0.2017\n",
            "Epoch 90/500\n",
            "84887/84887 [==============================] - 7s 87us/step - loss: 2.1298 - acc: 0.2018\n",
            "Epoch 91/500\n",
            "84887/84887 [==============================] - 7s 88us/step - loss: 2.1291 - acc: 0.2018\n",
            "Epoch 92/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1283 - acc: 0.2019\n",
            "Epoch 93/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1276 - acc: 0.2020\n",
            "Epoch 94/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1268 - acc: 0.2021\n",
            "Epoch 95/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 2.1261 - acc: 0.2022\n",
            "Epoch 96/500\n",
            "84887/84887 [==============================] - 7s 81us/step - loss: 2.1253 - acc: 0.2022\n",
            "Epoch 97/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1246 - acc: 0.2023\n",
            "Epoch 98/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.1238 - acc: 0.2023\n",
            "Epoch 99/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1231 - acc: 0.2024\n",
            "Epoch 100/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1224 - acc: 0.2025\n",
            "Epoch 101/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1217 - acc: 0.2025\n",
            "Epoch 102/500\n",
            "84887/84887 [==============================] - 6s 71us/step - loss: 2.1210 - acc: 0.2025\n",
            "Epoch 103/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.1203 - acc: 0.2026\n",
            "Epoch 104/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 2.1196 - acc: 0.2026\n",
            "Epoch 105/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1189 - acc: 0.2027\n",
            "Epoch 106/500\n",
            "84887/84887 [==============================] - 7s 83us/step - loss: 2.1183 - acc: 0.2028\n",
            "Epoch 107/500\n",
            "84887/84887 [==============================] - 6s 71us/step - loss: 2.1176 - acc: 0.2029\n",
            "Epoch 108/500\n",
            "84887/84887 [==============================] - 6s 71us/step - loss: 2.1169 - acc: 0.2029\n",
            "Epoch 109/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1162 - acc: 0.2029\n",
            "Epoch 110/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1156 - acc: 0.2029\n",
            "Epoch 111/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1150 - acc: 0.2029\n",
            "Epoch 112/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1143 - acc: 0.2030\n",
            "Epoch 113/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.1136 - acc: 0.2030\n",
            "Epoch 114/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1130 - acc: 0.2031\n",
            "Epoch 115/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.1124 - acc: 0.2032\n",
            "Epoch 116/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1117 - acc: 0.2032\n",
            "Epoch 117/500\n",
            "84887/84887 [==============================] - 6s 70us/step - loss: 2.1111 - acc: 0.2033\n",
            "Epoch 118/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.1104 - acc: 0.2034\n",
            "Epoch 119/500\n",
            "84887/84887 [==============================] - 7s 81us/step - loss: 2.1098 - acc: 0.2034\n",
            "Epoch 120/500\n",
            "84887/84887 [==============================] - 8s 90us/step - loss: 2.1092 - acc: 0.2034\n",
            "Epoch 121/500\n",
            "84887/84887 [==============================] - 8s 90us/step - loss: 2.1086 - acc: 0.2034\n",
            "Epoch 122/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.1079 - acc: 0.2035\n",
            "Epoch 123/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.1073 - acc: 0.2035\n",
            "Epoch 124/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.1067 - acc: 0.2036\n",
            "Epoch 125/500\n",
            "84887/84887 [==============================] - 9s 108us/step - loss: 2.1061 - acc: 0.2037\n",
            "Epoch 126/500\n",
            "84887/84887 [==============================] - 9s 112us/step - loss: 2.1055 - acc: 0.2038\n",
            "Epoch 127/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.1049 - acc: 0.2038\n",
            "Epoch 128/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.1042 - acc: 0.2039\n",
            "Epoch 129/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.1036 - acc: 0.2040\n",
            "Epoch 130/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.1030 - acc: 0.2040\n",
            "Epoch 131/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.1024 - acc: 0.2040\n",
            "Epoch 132/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.1018 - acc: 0.2041\n",
            "Epoch 133/500\n",
            "84887/84887 [==============================] - 11s 132us/step - loss: 2.1012 - acc: 0.2041\n",
            "Epoch 134/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.1006 - acc: 0.2041\n",
            "Epoch 135/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.1000 - acc: 0.2041\n",
            "Epoch 136/500\n",
            "84887/84887 [==============================] - 10s 123us/step - loss: 2.0994 - acc: 0.2042\n",
            "Epoch 137/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.0988 - acc: 0.2041\n",
            "Epoch 138/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0983 - acc: 0.2041\n",
            "Epoch 139/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0977 - acc: 0.2042\n",
            "Epoch 140/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0971 - acc: 0.2041\n",
            "Epoch 141/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0965 - acc: 0.2042\n",
            "Epoch 142/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0959 - acc: 0.2043\n",
            "Epoch 143/500\n",
            "84887/84887 [==============================] - 10s 119us/step - loss: 2.0953 - acc: 0.2043\n",
            "Epoch 144/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0947 - acc: 0.2044\n",
            "Epoch 145/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0941 - acc: 0.2044\n",
            "Epoch 146/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0935 - acc: 0.2044\n",
            "Epoch 147/500\n",
            "84887/84887 [==============================] - 10s 121us/step - loss: 2.0930 - acc: 0.2045\n",
            "Epoch 148/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0924 - acc: 0.2045\n",
            "Epoch 149/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0918 - acc: 0.2046\n",
            "Epoch 150/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0912 - acc: 0.2046\n",
            "Epoch 151/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0906 - acc: 0.2047\n",
            "Epoch 152/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0901 - acc: 0.2048\n",
            "Epoch 153/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0895 - acc: 0.2048\n",
            "Epoch 154/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0889 - acc: 0.2048\n",
            "Epoch 155/500\n",
            "84887/84887 [==============================] - 10s 120us/step - loss: 2.0883 - acc: 0.2049\n",
            "Epoch 156/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0878 - acc: 0.2050\n",
            "Epoch 157/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0872 - acc: 0.2050\n",
            "Epoch 158/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0866 - acc: 0.2050\n",
            "Epoch 159/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0861 - acc: 0.2051\n",
            "Epoch 160/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0855 - acc: 0.2051\n",
            "Epoch 161/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0849 - acc: 0.2052\n",
            "Epoch 162/500\n",
            "84887/84887 [==============================] - 9s 108us/step - loss: 2.0844 - acc: 0.2052\n",
            "Epoch 163/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0838 - acc: 0.2053\n",
            "Epoch 164/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0832 - acc: 0.2053\n",
            "Epoch 165/500\n",
            "84887/84887 [==============================] - 11s 135us/step - loss: 2.0827 - acc: 0.2054\n",
            "Epoch 166/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0821 - acc: 0.2053\n",
            "Epoch 167/500\n",
            "84887/84887 [==============================] - 11s 126us/step - loss: 2.0815 - acc: 0.2054\n",
            "Epoch 168/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0810 - acc: 0.2055\n",
            "Epoch 169/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0804 - acc: 0.2056\n",
            "Epoch 170/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0799 - acc: 0.2056\n",
            "Epoch 171/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0793 - acc: 0.2056\n",
            "Epoch 172/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0788 - acc: 0.2057\n",
            "Epoch 173/500\n",
            "84887/84887 [==============================] - 10s 120us/step - loss: 2.0782 - acc: 0.2057\n",
            "Epoch 174/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0777 - acc: 0.2058\n",
            "Epoch 175/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0771 - acc: 0.2058\n",
            "Epoch 176/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0766 - acc: 0.2058\n",
            "Epoch 177/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0760 - acc: 0.2059\n",
            "Epoch 178/500\n",
            "84887/84887 [==============================] - 9s 108us/step - loss: 2.0755 - acc: 0.2059\n",
            "Epoch 179/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0749 - acc: 0.2060\n",
            "Epoch 180/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0744 - acc: 0.2060\n",
            "Epoch 181/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0738 - acc: 0.2061\n",
            "Epoch 182/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.0733 - acc: 0.2061\n",
            "Epoch 183/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0727 - acc: 0.2061\n",
            "Epoch 184/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0722 - acc: 0.2062\n",
            "Epoch 185/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0716 - acc: 0.2062\n",
            "Epoch 186/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0711 - acc: 0.2063\n",
            "Epoch 187/500\n",
            "84887/84887 [==============================] - 10s 119us/step - loss: 2.0706 - acc: 0.2063\n",
            "Epoch 188/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0700 - acc: 0.2064\n",
            "Epoch 189/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0695 - acc: 0.2064\n",
            "Epoch 190/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0689 - acc: 0.2064\n",
            "Epoch 191/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0684 - acc: 0.2065\n",
            "Epoch 192/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0679 - acc: 0.2065\n",
            "Epoch 193/500\n",
            "84887/84887 [==============================] - 8s 95us/step - loss: 2.0673 - acc: 0.2065\n",
            "Epoch 194/500\n",
            "84887/84887 [==============================] - 8s 96us/step - loss: 2.0668 - acc: 0.2065\n",
            "Epoch 195/500\n",
            "84887/84887 [==============================] - 8s 97us/step - loss: 2.0663 - acc: 0.2067\n",
            "Epoch 196/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0658 - acc: 0.2067\n",
            "Epoch 197/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0652 - acc: 0.2068\n",
            "Epoch 198/500\n",
            "84887/84887 [==============================] - 8s 92us/step - loss: 2.0647 - acc: 0.2069\n",
            "Epoch 199/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 2.0642 - acc: 0.2069\n",
            "Epoch 200/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 2.0636 - acc: 0.2070\n",
            "Epoch 201/500\n",
            "84887/84887 [==============================] - 7s 88us/step - loss: 2.0631 - acc: 0.2070\n",
            "Epoch 202/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0626 - acc: 0.2070\n",
            "Epoch 203/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0621 - acc: 0.2071\n",
            "Epoch 204/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 2.0615 - acc: 0.2071\n",
            "Epoch 205/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0610 - acc: 0.2071\n",
            "Epoch 206/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0605 - acc: 0.2072\n",
            "Epoch 207/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0600 - acc: 0.2073\n",
            "Epoch 208/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0595 - acc: 0.2073\n",
            "Epoch 209/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0590 - acc: 0.2074\n",
            "Epoch 210/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0584 - acc: 0.2075\n",
            "Epoch 211/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0579 - acc: 0.2075\n",
            "Epoch 212/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0574 - acc: 0.2077\n",
            "Epoch 213/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0569 - acc: 0.2078\n",
            "Epoch 214/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0564 - acc: 0.2080\n",
            "Epoch 215/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0559 - acc: 0.2080\n",
            "Epoch 216/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0554 - acc: 0.2081\n",
            "Epoch 217/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0549 - acc: 0.2081\n",
            "Epoch 218/500\n",
            "84887/84887 [==============================] - 6s 71us/step - loss: 2.0544 - acc: 0.2082\n",
            "Epoch 219/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0539 - acc: 0.2082\n",
            "Epoch 220/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.0534 - acc: 0.2083\n",
            "Epoch 221/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0529 - acc: 0.2084\n",
            "Epoch 222/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0524 - acc: 0.2083\n",
            "Epoch 223/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0519 - acc: 0.2085\n",
            "Epoch 224/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0514 - acc: 0.2086\n",
            "Epoch 225/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0509 - acc: 0.2088\n",
            "Epoch 226/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0504 - acc: 0.2089\n",
            "Epoch 227/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0499 - acc: 0.2089\n",
            "Epoch 228/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0494 - acc: 0.2089\n",
            "Epoch 229/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0489 - acc: 0.2090\n",
            "Epoch 230/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0484 - acc: 0.2090\n",
            "Epoch 231/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0479 - acc: 0.2091\n",
            "Epoch 232/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0474 - acc: 0.2092\n",
            "Epoch 233/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0469 - acc: 0.2094\n",
            "Epoch 234/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0464 - acc: 0.2093\n",
            "Epoch 235/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0459 - acc: 0.2094\n",
            "Epoch 236/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 2.0455 - acc: 0.2095\n",
            "Epoch 237/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0450 - acc: 0.2095\n",
            "Epoch 238/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0445 - acc: 0.2096\n",
            "Epoch 239/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0440 - acc: 0.2098\n",
            "Epoch 240/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0435 - acc: 0.2098\n",
            "Epoch 241/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0431 - acc: 0.2099\n",
            "Epoch 242/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0426 - acc: 0.2101\n",
            "Epoch 243/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0421 - acc: 0.2101\n",
            "Epoch 244/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0416 - acc: 0.2101\n",
            "Epoch 245/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0411 - acc: 0.2101\n",
            "Epoch 246/500\n",
            "84887/84887 [==============================] - 9s 106us/step - loss: 2.0407 - acc: 0.2102\n",
            "Epoch 247/500\n",
            "84887/84887 [==============================] - 9s 100us/step - loss: 2.0402 - acc: 0.2103\n",
            "Epoch 248/500\n",
            "84887/84887 [==============================] - 11s 124us/step - loss: 2.0397 - acc: 0.2103\n",
            "Epoch 249/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0392 - acc: 0.2104\n",
            "Epoch 250/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0387 - acc: 0.2106\n",
            "Epoch 251/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0383 - acc: 0.2106\n",
            "Epoch 252/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0378 - acc: 0.2106\n",
            "Epoch 253/500\n",
            "84887/84887 [==============================] - 10s 119us/step - loss: 2.0373 - acc: 0.2109\n",
            "Epoch 254/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0369 - acc: 0.2109\n",
            "Epoch 255/500\n",
            "84887/84887 [==============================] - 10s 122us/step - loss: 2.0364 - acc: 0.2111\n",
            "Epoch 256/500\n",
            "84887/84887 [==============================] - 10s 121us/step - loss: 2.0359 - acc: 0.2110\n",
            "Epoch 257/500\n",
            "84887/84887 [==============================] - 10s 119us/step - loss: 2.0354 - acc: 0.2110\n",
            "Epoch 258/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0350 - acc: 0.2112\n",
            "Epoch 259/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0345 - acc: 0.2114\n",
            "Epoch 260/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0340 - acc: 0.2116\n",
            "Epoch 261/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0335 - acc: 0.2117\n",
            "Epoch 262/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0331 - acc: 0.2118\n",
            "Epoch 263/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0326 - acc: 0.2119\n",
            "Epoch 264/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0321 - acc: 0.2120\n",
            "Epoch 265/500\n",
            "84887/84887 [==============================] - 10s 118us/step - loss: 2.0316 - acc: 0.2121\n",
            "Epoch 266/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0312 - acc: 0.2121\n",
            "Epoch 267/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.0307 - acc: 0.2123\n",
            "Epoch 268/500\n",
            "84887/84887 [==============================] - 9s 110us/step - loss: 2.0302 - acc: 0.2123\n",
            "Epoch 269/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0298 - acc: 0.2125\n",
            "Epoch 270/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0293 - acc: 0.2127\n",
            "Epoch 271/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0288 - acc: 0.2128\n",
            "Epoch 272/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0284 - acc: 0.2130\n",
            "Epoch 273/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0279 - acc: 0.2131\n",
            "Epoch 274/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.0275 - acc: 0.2134\n",
            "Epoch 275/500\n",
            "84887/84887 [==============================] - 9s 112us/step - loss: 2.0270 - acc: 0.2135\n",
            "Epoch 276/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0265 - acc: 0.2136\n",
            "Epoch 277/500\n",
            "84887/84887 [==============================] - 9s 108us/step - loss: 2.0261 - acc: 0.2137\n",
            "Epoch 278/500\n",
            "84887/84887 [==============================] - 11s 125us/step - loss: 2.0256 - acc: 0.2140\n",
            "Epoch 279/500\n",
            "84887/84887 [==============================] - 11s 134us/step - loss: 2.0252 - acc: 0.2142\n",
            "Epoch 280/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0247 - acc: 0.2143\n",
            "Epoch 281/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0242 - acc: 0.2144\n",
            "Epoch 282/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0238 - acc: 0.2146\n",
            "Epoch 283/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0233 - acc: 0.2148\n",
            "Epoch 284/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0229 - acc: 0.2149\n",
            "Epoch 285/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0224 - acc: 0.2152\n",
            "Epoch 286/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0220 - acc: 0.2153\n",
            "Epoch 287/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0215 - acc: 0.2156\n",
            "Epoch 288/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.0211 - acc: 0.2157\n",
            "Epoch 289/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0206 - acc: 0.2159\n",
            "Epoch 290/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0202 - acc: 0.2161\n",
            "Epoch 291/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0197 - acc: 0.2162\n",
            "Epoch 292/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0193 - acc: 0.2163\n",
            "Epoch 293/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0188 - acc: 0.2165\n",
            "Epoch 294/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0184 - acc: 0.2168\n",
            "Epoch 295/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0179 - acc: 0.2172\n",
            "Epoch 296/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0175 - acc: 0.2174\n",
            "Epoch 297/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0171 - acc: 0.2175\n",
            "Epoch 298/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0166 - acc: 0.2177\n",
            "Epoch 299/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0162 - acc: 0.2180\n",
            "Epoch 300/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0157 - acc: 0.2182\n",
            "Epoch 301/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.0153 - acc: 0.2185\n",
            "Epoch 302/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0149 - acc: 0.2187\n",
            "Epoch 303/500\n",
            "84887/84887 [==============================] - 10s 115us/step - loss: 2.0144 - acc: 0.2188\n",
            "Epoch 304/500\n",
            "84887/84887 [==============================] - 10s 117us/step - loss: 2.0140 - acc: 0.2191\n",
            "Epoch 305/500\n",
            "84887/84887 [==============================] - 10s 112us/step - loss: 2.0136 - acc: 0.2194\n",
            "Epoch 306/500\n",
            "84887/84887 [==============================] - 9s 112us/step - loss: 2.0131 - acc: 0.2196\n",
            "Epoch 307/500\n",
            "84887/84887 [==============================] - 9s 109us/step - loss: 2.0127 - acc: 0.2199\n",
            "Epoch 308/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0123 - acc: 0.2205\n",
            "Epoch 309/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0118 - acc: 0.2207\n",
            "Epoch 310/500\n",
            "84887/84887 [==============================] - 11s 135us/step - loss: 2.0114 - acc: 0.2209\n",
            "Epoch 311/500\n",
            "84887/84887 [==============================] - 11s 135us/step - loss: 2.0110 - acc: 0.2211\n",
            "Epoch 312/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0106 - acc: 0.2214\n",
            "Epoch 313/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 2.0101 - acc: 0.2216\n",
            "Epoch 314/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0097 - acc: 0.2219\n",
            "Epoch 315/500\n",
            "84887/84887 [==============================] - 9s 111us/step - loss: 2.0093 - acc: 0.2222\n",
            "Epoch 316/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 2.0089 - acc: 0.2225\n",
            "Epoch 317/500\n",
            "84887/84887 [==============================] - 10s 116us/step - loss: 2.0084 - acc: 0.2228\n",
            "Epoch 318/500\n",
            "84887/84887 [==============================] - 11s 129us/step - loss: 2.0080 - acc: 0.2232\n",
            "Epoch 319/500\n",
            "84887/84887 [==============================] - 11s 126us/step - loss: 2.0076 - acc: 0.2232\n",
            "Epoch 320/500\n",
            "84887/84887 [==============================] - 9s 105us/step - loss: 2.0072 - acc: 0.2236\n",
            "Epoch 321/500\n",
            "84887/84887 [==============================] - 8s 95us/step - loss: 2.0068 - acc: 0.2240\n",
            "Epoch 322/500\n",
            "84887/84887 [==============================] - 8s 99us/step - loss: 2.0063 - acc: 0.2243\n",
            "Epoch 323/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 2.0059 - acc: 0.2247\n",
            "Epoch 324/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0055 - acc: 0.2252\n",
            "Epoch 325/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 2.0051 - acc: 0.2255\n",
            "Epoch 326/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0047 - acc: 0.2259\n",
            "Epoch 327/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 2.0043 - acc: 0.2260\n",
            "Epoch 328/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0039 - acc: 0.2265\n",
            "Epoch 329/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0035 - acc: 0.2269\n",
            "Epoch 330/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0031 - acc: 0.2273\n",
            "Epoch 331/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 2.0027 - acc: 0.2276\n",
            "Epoch 332/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0023 - acc: 0.2280\n",
            "Epoch 333/500\n",
            "84887/84887 [==============================] - 6s 71us/step - loss: 2.0019 - acc: 0.2285\n",
            "Epoch 334/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 2.0015 - acc: 0.2290\n",
            "Epoch 335/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0011 - acc: 0.2291\n",
            "Epoch 336/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 2.0007 - acc: 0.2296\n",
            "Epoch 337/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 2.0003 - acc: 0.2300\n",
            "Epoch 338/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9999 - acc: 0.2306\n",
            "Epoch 339/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9995 - acc: 0.2311\n",
            "Epoch 340/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9991 - acc: 0.2314\n",
            "Epoch 341/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9987 - acc: 0.2318\n",
            "Epoch 342/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9983 - acc: 0.2324\n",
            "Epoch 343/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9979 - acc: 0.2329\n",
            "Epoch 344/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9975 - acc: 0.2336\n",
            "Epoch 345/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9971 - acc: 0.2344\n",
            "Epoch 346/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9968 - acc: 0.2350\n",
            "Epoch 347/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9964 - acc: 0.2357\n",
            "Epoch 348/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9960 - acc: 0.2361\n",
            "Epoch 349/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9956 - acc: 0.2365\n",
            "Epoch 350/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 1.9952 - acc: 0.2368\n",
            "Epoch 351/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 1.9948 - acc: 0.2373\n",
            "Epoch 352/500\n",
            "84887/84887 [==============================] - 7s 81us/step - loss: 1.9945 - acc: 0.2378\n",
            "Epoch 353/500\n",
            "84887/84887 [==============================] - 10s 114us/step - loss: 1.9941 - acc: 0.2380\n",
            "Epoch 354/500\n",
            "84887/84887 [==============================] - 6s 71us/step - loss: 1.9937 - acc: 0.2384\n",
            "Epoch 355/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9933 - acc: 0.2391\n",
            "Epoch 356/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9929 - acc: 0.2394\n",
            "Epoch 357/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9926 - acc: 0.2397\n",
            "Epoch 358/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9922 - acc: 0.2405\n",
            "Epoch 359/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9918 - acc: 0.2410\n",
            "Epoch 360/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9914 - acc: 0.2414\n",
            "Epoch 361/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9911 - acc: 0.2420\n",
            "Epoch 362/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9907 - acc: 0.2424\n",
            "Epoch 363/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9903 - acc: 0.2430\n",
            "Epoch 364/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9900 - acc: 0.2437\n",
            "Epoch 365/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9896 - acc: 0.2443\n",
            "Epoch 366/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9892 - acc: 0.2448\n",
            "Epoch 367/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9889 - acc: 0.2453\n",
            "Epoch 368/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9885 - acc: 0.2460\n",
            "Epoch 369/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9881 - acc: 0.2465\n",
            "Epoch 370/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 1.9878 - acc: 0.2472\n",
            "Epoch 371/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9874 - acc: 0.2476\n",
            "Epoch 372/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9870 - acc: 0.2483\n",
            "Epoch 373/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9866 - acc: 0.2490\n",
            "Epoch 374/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9863 - acc: 0.2496\n",
            "Epoch 375/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9859 - acc: 0.2499\n",
            "Epoch 376/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9855 - acc: 0.2504\n",
            "Epoch 377/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9851 - acc: 0.2510\n",
            "Epoch 378/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9847 - acc: 0.2515\n",
            "Epoch 379/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9843 - acc: 0.2520\n",
            "Epoch 380/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9840 - acc: 0.2524\n",
            "Epoch 381/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9836 - acc: 0.2531\n",
            "Epoch 382/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9832 - acc: 0.2536\n",
            "Epoch 383/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9828 - acc: 0.2542\n",
            "Epoch 384/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9824 - acc: 0.2546\n",
            "Epoch 385/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9821 - acc: 0.2553\n",
            "Epoch 386/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9817 - acc: 0.2558\n",
            "Epoch 387/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9813 - acc: 0.2565\n",
            "Epoch 388/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9809 - acc: 0.2571\n",
            "Epoch 389/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9806 - acc: 0.2576\n",
            "Epoch 390/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 1.9802 - acc: 0.2582\n",
            "Epoch 391/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9799 - acc: 0.2586\n",
            "Epoch 392/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9795 - acc: 0.2594\n",
            "Epoch 393/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9791 - acc: 0.2599\n",
            "Epoch 394/500\n",
            "84887/84887 [==============================] - 6s 73us/step - loss: 1.9788 - acc: 0.2603\n",
            "Epoch 395/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 1.9784 - acc: 0.2610\n",
            "Epoch 396/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9780 - acc: 0.2617\n",
            "Epoch 397/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9777 - acc: 0.2622\n",
            "Epoch 398/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9773 - acc: 0.2629\n",
            "Epoch 399/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9770 - acc: 0.2638\n",
            "Epoch 400/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9766 - acc: 0.2644\n",
            "Epoch 401/500\n",
            "84887/84887 [==============================] - 10s 113us/step - loss: 1.9762 - acc: 0.2650\n",
            "Epoch 402/500\n",
            "84887/84887 [==============================] - 7s 82us/step - loss: 1.9759 - acc: 0.2656\n",
            "Epoch 403/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9755 - acc: 0.2660\n",
            "Epoch 404/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9752 - acc: 0.2665\n",
            "Epoch 405/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9748 - acc: 0.2671\n",
            "Epoch 406/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9745 - acc: 0.2676\n",
            "Epoch 407/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9741 - acc: 0.2683\n",
            "Epoch 408/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9738 - acc: 0.2689\n",
            "Epoch 409/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9734 - acc: 0.2695\n",
            "Epoch 410/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9731 - acc: 0.2701\n",
            "Epoch 411/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9727 - acc: 0.2706\n",
            "Epoch 412/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9724 - acc: 0.2711\n",
            "Epoch 413/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9720 - acc: 0.2718\n",
            "Epoch 414/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9717 - acc: 0.2726\n",
            "Epoch 415/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9713 - acc: 0.2733\n",
            "Epoch 416/500\n",
            "84887/84887 [==============================] - 6s 72us/step - loss: 1.9710 - acc: 0.2740\n",
            "Epoch 417/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9707 - acc: 0.2746\n",
            "Epoch 418/500\n",
            "84887/84887 [==============================] - 6s 77us/step - loss: 1.9703 - acc: 0.2752\n",
            "Epoch 419/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9700 - acc: 0.2757\n",
            "Epoch 420/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9696 - acc: 0.2763\n",
            "Epoch 421/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9693 - acc: 0.2770\n",
            "Epoch 422/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9690 - acc: 0.2775\n",
            "Epoch 423/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9686 - acc: 0.2783\n",
            "Epoch 424/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9683 - acc: 0.2790\n",
            "Epoch 425/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9679 - acc: 0.2799\n",
            "Epoch 426/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9676 - acc: 0.2805\n",
            "Epoch 427/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9673 - acc: 0.2812\n",
            "Epoch 428/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9669 - acc: 0.2817\n",
            "Epoch 429/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9666 - acc: 0.2822\n",
            "Epoch 430/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9663 - acc: 0.2828\n",
            "Epoch 431/500\n",
            "84887/84887 [==============================] - 6s 74us/step - loss: 1.9659 - acc: 0.2836\n",
            "Epoch 432/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9656 - acc: 0.2841\n",
            "Epoch 433/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9653 - acc: 0.2845\n",
            "Epoch 434/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9649 - acc: 0.2852\n",
            "Epoch 435/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9646 - acc: 0.2857\n",
            "Epoch 436/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9643 - acc: 0.2863\n",
            "Epoch 437/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9640 - acc: 0.2868\n",
            "Epoch 438/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9636 - acc: 0.2872\n",
            "Epoch 439/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9633 - acc: 0.2879\n",
            "Epoch 440/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9630 - acc: 0.2886\n",
            "Epoch 441/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9626 - acc: 0.2892\n",
            "Epoch 442/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9623 - acc: 0.2897\n",
            "Epoch 443/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9620 - acc: 0.2904\n",
            "Epoch 444/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 1.9617 - acc: 0.2908\n",
            "Epoch 445/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9613 - acc: 0.2915\n",
            "Epoch 446/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9610 - acc: 0.2922\n",
            "Epoch 447/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9607 - acc: 0.2925\n",
            "Epoch 448/500\n",
            "84887/84887 [==============================] - 8s 93us/step - loss: 1.9604 - acc: 0.2929\n",
            "Epoch 449/500\n",
            "84887/84887 [==============================] - 8s 94us/step - loss: 1.9600 - acc: 0.2934\n",
            "Epoch 450/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9597 - acc: 0.2941\n",
            "Epoch 451/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9594 - acc: 0.2944\n",
            "Epoch 452/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9591 - acc: 0.2950\n",
            "Epoch 453/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9588 - acc: 0.2954\n",
            "Epoch 454/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9584 - acc: 0.2958\n",
            "Epoch 455/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9581 - acc: 0.2961\n",
            "Epoch 456/500\n",
            "84887/84887 [==============================] - 6s 75us/step - loss: 1.9578 - acc: 0.2967\n",
            "Epoch 457/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 1.9575 - acc: 0.2972\n",
            "Epoch 458/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9572 - acc: 0.2978\n",
            "Epoch 459/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9568 - acc: 0.2982\n",
            "Epoch 460/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9565 - acc: 0.2987\n",
            "Epoch 461/500\n",
            "84887/84887 [==============================] - 6s 77us/step - loss: 1.9562 - acc: 0.2990\n",
            "Epoch 462/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9559 - acc: 0.2994\n",
            "Epoch 463/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9556 - acc: 0.2999\n",
            "Epoch 464/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9553 - acc: 0.3003\n",
            "Epoch 465/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9550 - acc: 0.3008\n",
            "Epoch 466/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9547 - acc: 0.3012\n",
            "Epoch 467/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9543 - acc: 0.3018\n",
            "Epoch 468/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9540 - acc: 0.3021\n",
            "Epoch 469/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9537 - acc: 0.3025\n",
            "Epoch 470/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9534 - acc: 0.3030\n",
            "Epoch 471/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9531 - acc: 0.3035\n",
            "Epoch 472/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9528 - acc: 0.3041\n",
            "Epoch 473/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9525 - acc: 0.3045\n",
            "Epoch 474/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 1.9522 - acc: 0.3052\n",
            "Epoch 475/500\n",
            "84887/84887 [==============================] - 6s 76us/step - loss: 1.9519 - acc: 0.3055\n",
            "Epoch 476/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9515 - acc: 0.3060\n",
            "Epoch 477/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9512 - acc: 0.3064\n",
            "Epoch 478/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9509 - acc: 0.3069\n",
            "Epoch 479/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9506 - acc: 0.3072\n",
            "Epoch 480/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9503 - acc: 0.3074\n",
            "Epoch 481/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9500 - acc: 0.3079\n",
            "Epoch 482/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9497 - acc: 0.3084\n",
            "Epoch 483/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9494 - acc: 0.3088\n",
            "Epoch 484/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 1.9491 - acc: 0.3096\n",
            "Epoch 485/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9487 - acc: 0.3100\n",
            "Epoch 486/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9484 - acc: 0.3103\n",
            "Epoch 487/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9481 - acc: 0.3108\n",
            "Epoch 488/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9478 - acc: 0.3113\n",
            "Epoch 489/500\n",
            "84887/84887 [==============================] - 7s 77us/step - loss: 1.9475 - acc: 0.3117\n",
            "Epoch 490/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9471 - acc: 0.3121\n",
            "Epoch 491/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9468 - acc: 0.3124\n",
            "Epoch 492/500\n",
            "84887/84887 [==============================] - 7s 80us/step - loss: 1.9465 - acc: 0.3129\n",
            "Epoch 493/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9462 - acc: 0.3129\n",
            "Epoch 494/500\n",
            "84887/84887 [==============================] - 8s 90us/step - loss: 1.9459 - acc: 0.3134\n",
            "Epoch 495/500\n",
            "84887/84887 [==============================] - 7s 85us/step - loss: 1.9456 - acc: 0.3137\n",
            "Epoch 496/500\n",
            "84887/84887 [==============================] - 8s 91us/step - loss: 1.9452 - acc: 0.3141\n",
            "Epoch 497/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9449 - acc: 0.3143\n",
            "Epoch 498/500\n",
            "84887/84887 [==============================] - 7s 79us/step - loss: 1.9446 - acc: 0.3146\n",
            "Epoch 499/500\n",
            "84887/84887 [==============================] - 7s 78us/step - loss: 1.9443 - acc: 0.3151\n",
            "Epoch 500/500\n",
            "84887/84887 [==============================] - 7s 81us/step - loss: 1.9440 - acc: 0.3154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xPf7GsqobPBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stackedModel.model.save('model_1_12_stars.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hpv1hP2njKVx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model_1_12_stars.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MxFnI-hBErqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stackedModel.model.save_weights('model__weights_1_12_stars.h5')\n",
        "files.download('model__weights_1_12_stars.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJQzOWn8yU2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_user = pd.read_csv(\"user_FeatureVec_valid.csv\").drop([\"user_id\",\"review_id\",\"business_id\",\"1overN\",\"2overN\",\"percentile\"],axis=1).fillna(0)\n",
        "valid_business = pd.read_csv(\"business_FeatureVec_valid.csv\").drop([\"business_id\",\"review_id\",\"user_id\",\"1overN\",\"2overN\",\"percentile\"],axis=1).fillna(0)\n",
        "stacked= valid_business[['attributes.Ambience.casual','attributes.BikeParking','attributes.BusinessAcceptsCreditCards','attributes.BusinessParking.street','attributes.HasTV','attributes.RestaurantsDelivery','attributes.GoodForMeal.breakfast','attributes.GoodForMeal.brunch','attributes.GoodForMeal.dessert','attributes.GoodForMeal.dinner','attributes.GoodForMeal.latenight','attributes.GoodForMeal.lunch','attributes.Alcohol','attributes.NoiseLevel']].stack()\n",
        "valid_business[['attributes.Ambience.casual','attributes.BikeParking','attributes.BusinessAcceptsCreditCards','attributes.BusinessParking.street','attributes.HasTV','attributes.RestaurantsDelivery','attributes.GoodForMeal.breakfast','attributes.GoodForMeal.brunch','attributes.GoodForMeal.dessert','attributes.GoodForMeal.dinner','attributes.GoodForMeal.latenight','attributes.GoodForMeal.lunch','attributes.Alcohol','attributes.NoiseLevel']]=pd.Series(stacked.factorize()[0], index=stacked.index).unstack()\n",
        "#reviews = pd.read_csv(\"user_business_reviewVec.csv\")['review_id']\n",
        "\n",
        "valid_rating_csv = pd.read_csv(\"Dataset/PA/Restaurants/valid/PA_valid_yelp_academic_dataset_review.csv\")\n",
        "valid_rating_csv_stars = valid_rating_csv['stars']\n",
        "encoded_rating = to_categorical(np.array(list(valid_rating_csv_stars)))\n",
        "encoded_rating_valid = encoded_rating[:,1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zqMWByNC4KbP",
        "colab_type": "code",
        "outputId": "b44e304a-7880-4647-efbe-feea1010ced5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "valid_user.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27255, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "a_LeWP8c4Mq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_user = pd.read_csv(\"LDA Modelling/results/test/user_FeatureVec_test.csv\").drop([\"user_id\",\"review_id\",\"business_id\",\"1overN\",\"2overN\",\"percentile\"],axis=1).fillna(0)\n",
        "test_business = pd.read_csv(\"LDA Modelling/results/test/business_FeatureVec_test.csv\").drop([\"business_id\",\"review_id\",\"user_id\",\"1overN\",\"2overN\",\"percentile\"],axis=1).fillna(0)\n",
        "stacked= test_business[['attributes.Ambience.casual','attributes.BikeParking','attributes.BusinessAcceptsCreditCards','attributes.BusinessParking.street','attributes.HasTV','attributes.RestaurantsDelivery','attributes.GoodForMeal.breakfast','attributes.GoodForMeal.brunch','attributes.GoodForMeal.dessert','attributes.GoodForMeal.dinner','attributes.GoodForMeal.latenight','attributes.GoodForMeal.lunch','attributes.Alcohol','attributes.NoiseLevel']].stack()\n",
        "test_business[['attributes.Ambience.casual','attributes.BikeParking','attributes.BusinessAcceptsCreditCards','attributes.BusinessParking.street','attributes.HasTV','attributes.RestaurantsDelivery','attributes.GoodForMeal.breakfast','attributes.GoodForMeal.brunch','attributes.GoodForMeal.dessert','attributes.GoodForMeal.dinner','attributes.GoodForMeal.latenight','attributes.GoodForMeal.lunch','attributes.Alcohol','attributes.NoiseLevel']]=pd.Series(stacked.factorize()[0], index=stacked.index).unstack()\n",
        "#test_business = test_business.loc[:,[\"topic_0\",\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\",\"topic_6\",\"topic_7\",\"topic_8\",\"topic_9\",\"topic_10\",\"topic_11\",\"topic_12\",\"topic_13\",\"topic_14\",\"topic_15\",\"topic_16\",\"topic_17\",\"topic_18\",\"topic_19\",\"business_stars\",\"is_open\",\"attributes.Ambience.casual\",\"attributes.BikeParking\",\"attributes.BusinessAcceptsCreditCards\",\"attributes.BusinessParking.street\",\"attributes.HasTV\",\"attributes.RestaurantsDelivery\",\"attributes.GoodForMeal.breakfast\",\"attributes.GoodForMeal.brunch\",\"attributes.GoodForMeal.dessert\",\"attributes.GoodForMeal.dinner\",\"attributes.GoodForMeal.latenight\",\"attributes.GoodForMeal.lunch\",\"attributes.Alcohol\",\"attributes.NoiseLevel\",\"attributes.RestaurantsPriceRange2\"]]\n",
        "\n",
        "#reviews = pd.read_csv(\"user_business_reviewVec.csv\")['review_id']\n",
        "\n",
        "test_rating_csv = pd.read_csv(\"Dataset/PA/Restaurants/test/PA_test_yelp_academic_dataset_review.csv\")\n",
        "test_rating_csv_stars = test_rating_csv['stars']\n",
        "encoded_rating = to_categorical(np.array(list(test_rating_csv_stars)))\n",
        "encoded_rating_test = encoded_rating[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRXYSwgg0M1m",
        "colab_type": "code",
        "outputId": "795ec54d-e824-46d5-bc28-cc5c5e66d928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "valid_inputs = [valid_user,valid_business]\n",
        "predictions_valid = stackedModel.model.predict(valid_inputs)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "score_valid = np.sqrt(mean_squared_error(encoded_rating_valid,predictions))\n",
        "print(\"RMSE valid: \",score_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE valid:  0.39890584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e7Qhezxc1b0e",
        "colab_type": "code",
        "outputId": "ddd8738c-7cbe-47e6-facb-61b743080f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "train_inputs = [train_user,train_business]\n",
        "predictions = stackedModel.model.predict(train_inputs)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "score_valid = np.sqrt(mean_squared_error(encoded_rating_,predictions))\n",
        "\n",
        "print(\"RMSE train: \",score_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE train:  0.40145263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CoDFn7vG1tzV",
        "colab_type": "code",
        "outputId": "0b995756-9c6c-4dbe-ef5f-82bb24aa4691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "test_inputs = [test_user,test_business]\n",
        "predictions_test = stackedModel.model.predict(test_inputs)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "score_test = np.sqrt(mean_squared_error(encoded_rating_test,predictions))\n",
        "print(\"RMSE test: \",score_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE test:  0.39853543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GrYCNEca6QRJ",
        "colab_type": "code",
        "outputId": "1d0a2ffc-0e48-43e5-adbf-dacd2a617036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "score = stackedModel.model.evaluate(test_inputs,encoded_rating_test)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65591/65591 [==============================] - 2s 33us/step\n",
            "[1.6916372785155165, 0.33789696757404236]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GuID1wwS9fmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_inputs = [test_user,test_business]\n",
        "predictions = stackedModel.model.predict(test_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Gf19lFL-NFq",
        "colab_type": "code",
        "outputId": "dd475709-4a9a-4c84-8145-db7bca312c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "score = stackedModel.model.evaluate(test_inputs,encoded_rating_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65591/65591 [==============================] - 2s 28us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KdF9AvhYKPXP",
        "colab_type": "code",
        "outputId": "b7c5b97f-701c-49d1-db9c-daf46168f4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3845180452857757, 0.4405939839257242]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    }
  ]
}
