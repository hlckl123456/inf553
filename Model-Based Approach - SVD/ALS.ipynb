{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"/Users/arun/Downloads/Restaurants/train/PA_train_yelp_academic_dataset_review.csv\"\n",
    "test_dataset = '/Users/arun/Downloads/Restaurants/test/PA_test_yelp_academic_dataset_review.csv'\n",
    "valid_dataset = '/Users/arun/Downloads/Restaurants/valid/PA_valid_yelp_academic_dataset_review.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset='/Users/arun/Downloads/datasets/yelp/NV/train/NV_train_yelp_academic_dataset_review.csv'\n",
    "# #dev_dataset='/Users/arun/Downloads/datasets/yelp/PA/Restaurants/valid/PA_valid_yelp_academic_dataset_review.csv'\n",
    "# test_dataset='/Users/arun/Downloads/datasets/yelp/NV/test/NV_test_yelp_academic_dataset_review.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "# Make sure pyspark version and spark version match\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark.SparkContext.setCheckpointDir(sc, '/tmp/spark-checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"graph analysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.csv(train_dataset, header=True, quote='\"', escape='\"', multiLine=True)\n",
    "valid_df = spark.read.csv(valid_dataset, header=True, quote='\"', escape='\"', multiLine=True)\n",
    "test_df = spark.read.csv(test_dataset, header=True, quote='\"', escape='\"', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['funny',\n",
       " 'user_id',\n",
       " 'review_id',\n",
       " 'text',\n",
       " 'business_id',\n",
       " 'stars',\n",
       " 'date',\n",
       " 'useful',\n",
       " 'cool',\n",
       " '1overN',\n",
       " '2overN',\n",
       " 'percentile\\r']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = train_df.select(\"user_id\", \"business_id\", \"stars\").rdd.map(lambda (user, business, star): (user, business, int(star)))\n",
    "valid_rdd = valid_df.select(\"user_id\", \"business_id\", \"stars\").rdd.map(lambda (user, business, star): (user, business, int(star)))\n",
    "test_rdd = test_df.select(\"user_id\", \"business_id\", \"stars\").rdd.map(lambda (user, business, star): (user, business, int(star)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84887"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'eG6HneK9zLcuZpVuKcsCGQ', u'XqNDr54eLDLRfZwo4l4dVA', 4),\n",
       " (u'AlzerMK7z84E4KU6GjPzIQ', u'PyTHy9VPOhBCiGLsi-PA2Q', 3),\n",
       " (u'AlzerMK7z84E4KU6GjPzIQ', u'zzwhN7x37nyjP0ZM8oiHmw', 4),\n",
       " (u'AlzerMK7z84E4KU6GjPzIQ', u'Ul6JwluSTm12PVDIqnNaTg', 4),\n",
       " (u'AlzerMK7z84E4KU6GjPzIQ', u'2Ezp_HYCIVE-h7hpBBvtxw', 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, dev, test):\n",
    "    \n",
    "    train_dev_test = sc.union([train, dev, test])\n",
    "    \n",
    "    user_index = train_dev_test.map(lambda x: x[0]).distinct().zipWithIndex()\n",
    "    bus_index = train_dev_test.map(lambda x: x[1]).distinct().zipWithIndex()\n",
    "    \n",
    "    train_index = train.map(lambda x: (x[0], (x[1], x[2]))).join(user_index)\\\n",
    "    .map(lambda x: (x[1][0][0], (x[1][0][1], x[1][1]))).join(bus_index)\\\n",
    "    .map(lambda x: (x[1][0][1], x[1][1], int(x[1][0][0])))\n",
    "    \n",
    "    dev_index = dev.map(lambda x: (x[0], (x[1], x[2]))).join(user_index)\\\n",
    "    .map(lambda x: (x[1][0][0], (x[1][0][1], x[1][1]))).join(bus_index)\\\n",
    "    .map(lambda x: (x[1][0][1], x[1][1], int(x[1][0][0])))\n",
    "    \n",
    "    test_index = test.map(lambda x: (x[0], (x[1], x[2]))).join(user_index)\\\n",
    "    .map(lambda x: (x[1][0][0], (x[1][0][1], x[1][1]))).join(bus_index)\\\n",
    "    .map(lambda x: (x[1][0][1], x[1][1], int(x[1][0][0])))\n",
    "    \n",
    "    return (train_index, dev_index, test_index, user_index, bus_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, dev, test, user_index, bus_index = preprocess_data(train_rdd, valid_rdd, test_rdd)\n",
    "train, dev, test, user_index, bus_index = preprocess_data(train_rdd, valid_rdd, test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.checkpoint()\n",
    "dev.checkpoint()\n",
    "test.checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import numpy as np\n",
    "\n",
    "ranks = [5, 10]\n",
    "lambda_ = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "iterations = [30]\n",
    "\n",
    "def grid_search(train, dev, dev_actual_kv):\n",
    "    for rank in ranks:\n",
    "        for l in lambda_:\n",
    "            for it in iterations:\n",
    "                print rank, l, it\n",
    "\n",
    "                model = ALS.train(train, rank, lambda_=l, iterations=it, seed=10)\n",
    "                predictions = model.predictAll(dev)\n",
    "                predictions_kv = predictions.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "                test_merged = predictions_kv.join(dev_actual_kv)\n",
    "                mse = test_merged.map(lambda x: (x[1][0] - x[1][1]) ** 2).mean()\n",
    "\n",
    "                print rank, l, it, np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = dev.map(lambda x: (x[0], x[1]))\n",
    "dev_actual_kv = dev.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "# test_data = test.map(lambda x: (x[0], x[1]))\n",
    "# test_actual_kv = test.map(lambda x: ((x[0], x[1]), x[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.1 30\n",
      "5 0.1 30 1.5111275867367675\n",
      "5 0.2 30\n",
      "5 0.2 30 1.421761059250058\n",
      "5 0.3 30\n",
      "5 0.3 30 1.3884958167873793\n",
      "5 0.4 30\n",
      "5 0.4 30 1.3785463561970674\n",
      "5 0.5 30\n",
      "5 0.5 30 1.3878138849424924\n",
      "10 0.1 30\n",
      "10 0.1 30 1.5126671549280883\n",
      "10 0.2 30\n",
      "10 0.2 30 1.424092589355232\n",
      "10 0.3 30\n",
      "10 0.3 30 1.3886587616343984\n",
      "10 0.4 30\n",
      "10 0.4 30 1.377688186847247\n",
      "10 0.5 30\n",
      "10 0.5 30 1.3860366337064651\n"
     ]
    }
   ],
   "source": [
    "grid_search(train, dev_data, dev_actual_kv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "l = 0.4\n",
    "it = 100\n",
    "\n",
    "model = ALS.train(train, rank, lambda_=l, iterations=it, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65591"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.4 100 1.3979137792599632\n"
     ]
    }
   ],
   "source": [
    "test_data = test.map(lambda x: (x[0], x[1]))\n",
    "test_actual_kv = test.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "predictions = model.predictAll(test_data)\n",
    "predictions_kv = predictions.map(lambda x: ((x[0], x[1]), x[2]))\n",
    "test_merged = predictions_kv.join(test_actual_kv)\n",
    "mse = test_merged.map(lambda x: (x[1][0] - x[1][1]) ** 2).mean()\n",
    "\n",
    "print rank, l, it, np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 0.4 100 1.3979137792599632\n",
    "#HIT RATIO Score:  0.00506714801374\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendProductsForUsers(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommendations.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12072"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set()\n",
    "\n",
    "for row in train.collect():\n",
    "    train_set.add((row[0], row[1]))\n",
    "for row in dev.collect():\n",
    "    train_set.add((row[0], row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_list = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_index = dict()\n",
    "reverse_b_index = dict()\n",
    "\n",
    "for row in bus_index.collect():\n",
    "    b_index[row[0]] = row[1]\n",
    "    reverse_b_index[row[1]] = row[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_index = dict()\n",
    "reverse_u_index = dict()\n",
    "\n",
    "for row in user_index.collect():\n",
    "    u_index[row[0]] = row[1]\n",
    "    reverse_u_index[row[1]] = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, rec in recommendations:\n",
    "    recommendation_list[user] = []\n",
    "    for r in rec:\n",
    "        if ((user, r[1]) in train_set):\n",
    "            pass\n",
    "        else:\n",
    "            recommendation_list[user].append(reverse_b_index[r[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to user id, product id and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"als_predictions.txt\", \"w\") as outfile:\n",
    "    for user in recommendation_list:\n",
    "        line = reverse_u_index[user] + \",\"\n",
    "        line += \",\".join(recommendation_list[user])\n",
    "        \n",
    "        outfile.write(line + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the ones in train and dev and write the remaining results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
